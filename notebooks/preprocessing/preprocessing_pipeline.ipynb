{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßº Data Preprocessing Pipeline\n",
    "\n",
    "This notebook provides a comprehensive data preprocessing pipeline for the transport dataset from the year $2022$. The main goal is to clean and prepare the data for further analysis, ensuring its consistency and quality.\n",
    "\n",
    "The preprocessing pipeline includes the following steps:\n",
    "\n",
    "1. Loading data from the given files\n",
    "2. Translating column names\n",
    "3. Processing product IDs\n",
    "4. Processing transport types\n",
    "5. Downloading and loading BAV list (Betriebszentrale AV)\n",
    "6. Processing stop data\n",
    "7. Extracting stop data\n",
    "8. Processing arrival and departure times\n",
    "9. Handling inconsistent rows\n",
    "10. Extracting operator data\n",
    "11. Deleting unnecessary columns\n",
    "12. Adding delay columns\n",
    "13. Saving preprocessed data\n",
    "\n",
    "For memory considerations, the data is processed and saved day by day. A second step is performed using Spark, which is not included in this notebook, but can be found in the [üìÅ spark](../../spark) folder.\n",
    "\n",
    "Furthermore, data about operators and stops is provided in separate files. These files are also loaded and processed in this notebook.\n",
    "\n",
    "The processed data is saved in the `data/preprocessed` folder, as three separate files:\n",
    "- `data/preprocessed/operators.csv`\n",
    "- `data/preprocessed/stops.csv`\n",
    "- `data/preprocessed/transports.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "path_to_preprocessing = os.path.join('..', '..', 'src')\n",
    "sys.path.insert(0, path_to_preprocessing)\n",
    "\n",
    "from preprocessing.preprocessing_pipeline import preprocess_files\n",
    "from preprocessing.merge_data import merge_and_save_operator_data, merge_and_save_stop_data, merge_and_save_transport_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Found 253 valid file(s) in the data folder.\n"
     ]
    }
   ],
   "source": [
    "preprocess_files(\n",
    "    overwrite_existing_file=True,\n",
    "    print_progress=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_and_save_operator_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_and_save_stop_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
